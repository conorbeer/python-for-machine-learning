{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2 - Introduction to data\n",
    "\n",
    "### Libraries\n",
    "\n",
    "In this section, you will be introduced to the concept of libraries. You will further learn how to use some of the famous Python libraries, such as Scikit-Learn and Pandas. These libraries contain some built-in datasets that let you start exploring the commands without needing to download a dataset from an outside source. You can also download any interesting dataset from an outside source and start manipulating and processing the dataset using the Scikit-Learn and the Pandas libraries. Using the libraries' functions lets you use very complex codes without needing to write them from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/cbeer/Desktop/data-science-learning/machine-learning-in-python')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set working directory\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import os \n",
    "\n",
    "os.chdir(Path('C:/Users/cbeer/Desktop/data-science-learning/machine-learning-in-python'))\n",
    "\n",
    "Path.cwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset\n",
    "\n",
    "To load the Digits dataset, use the load_digits function from the sklearn.datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.datasets import load_digits # import a built-in dataset from Scikit-Learn\n",
    "\n",
    "dat = load_digits() # load digits dataset\n",
    "\n",
    "dat_2 = load_digits(as_frame=True) # return as dataframe\n",
    "\n",
    "dat_3 = load_digits(return_X_y=True) # return as x and y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this line of code is (1797, 64), which means that the dataset has 1,797 samples and each has a dimension of 64 (each image is 8 by 8 pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(dat.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing a sample image\n",
    "\n",
    "The following line of code shows you an example of the images in this dataset.\n",
    "Note: you will be introduced to visualization techniques and the Matplotlib library later in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15ce4cf8310>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(dat.images[400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing output \n",
    "\n",
    "The output is equal to 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(dat.target[400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Pandas\n",
    "\n",
    "Pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series.\n",
    "The name Pandas is derived from the term “Panel Data,” which is defined as the observation of the same data samples over a period of time.\n",
    "The Pandas library is considered the number one tool in data science and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # In this lesson, the Pandas library will be explicitly imported with the abbreviated name of pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV is short for Comma Separated Values. A CSV file is a text file that contains data in a comma-separated format.\n",
    "Each line represents a row and column; each row is separated by commas.\n",
    "Pandas reading a CSV file can be easily done using the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          CATEGORY       #    %\n",
      "0            RI Workshop/Info Session Participants  481251  NaN\n",
      "1                         Assisted Service Clients  183059  NaN\n",
      "2                Assisted Service Clients Age < 20   10984   6%\n",
      "3             Assisted Service Clients Age 20 -29    53087  29%\n",
      "4               Assisted Service Clients Age 30-44   62240  34%\n",
      "5              Assisted Service Clients Age 45 -54   38442  21%\n",
      "6                 Assisted Service Clients Age 55+   18306  10%\n",
      "7                                      Gender Male   93360  51%\n",
      "8                                    Gender Female   89699  49%\n",
      "9    Service Outcomes at exit Employed/Career Path  115426  63%\n",
      "10     Service Outcomes at exit Training/Education   27706  15%\n",
      "11    Customer Satisfaction (participant/employer)  501335  97%\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('employment_service.csv')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas head() function fetches the data samples at the top of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>#</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RI Workshop/Info Session Participants</td>\n",
       "      <td>481251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assisted Service Clients</td>\n",
       "      <td>183059</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assisted Service Clients Age &lt; 20</td>\n",
       "      <td>10984</td>\n",
       "      <td>6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assisted Service Clients Age 20 -29</td>\n",
       "      <td>53087</td>\n",
       "      <td>29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assisted Service Clients Age 30-44</td>\n",
       "      <td>62240</td>\n",
       "      <td>34%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                CATEGORY       #    %\n",
       "0  RI Workshop/Info Session Participants  481251  NaN\n",
       "1               Assisted Service Clients  183059  NaN\n",
       "2      Assisted Service Clients Age < 20   10984   6%\n",
       "3   Assisted Service Clients Age 20 -29    53087  29%\n",
       "4     Assisted Service Clients Age 30-44   62240  34%"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Data from Pandas' DataFrames\n",
    "You will need to extract data from columns or from rows.\n",
    "In the following section, you will learn about accessing elements of a Pandas DataFrame and extracting data from specific cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RI Workshop/Info Session Participants</td>\n",
       "      <td>481251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assisted Service Clients</td>\n",
       "      <td>183059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assisted Service Clients Age &lt; 20</td>\n",
       "      <td>10984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assisted Service Clients Age 20 -29</td>\n",
       "      <td>53087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assisted Service Clients Age 30-44</td>\n",
       "      <td>62240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Assisted Service Clients Age 45 -54</td>\n",
       "      <td>38442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Assisted Service Clients Age 55+</td>\n",
       "      <td>18306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gender Male</td>\n",
       "      <td>93360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gender Female</td>\n",
       "      <td>89699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Service Outcomes at exit Employed/Career Path</td>\n",
       "      <td>115426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Service Outcomes at exit Training/Education</td>\n",
       "      <td>27706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Customer Satisfaction (participant/employer)</td>\n",
       "      <td>501335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          CATEGORY       #\n",
       "0            RI Workshop/Info Session Participants  481251\n",
       "1                         Assisted Service Clients  183059\n",
       "2                Assisted Service Clients Age < 20   10984\n",
       "3             Assisted Service Clients Age 20 -29    53087\n",
       "4               Assisted Service Clients Age 30-44   62240\n",
       "5              Assisted Service Clients Age 45 -54   38442\n",
       "6                 Assisted Service Clients Age 55+   18306\n",
       "7                                      Gender Male   93360\n",
       "8                                    Gender Female   89699\n",
       "9    Service Outcomes at exit Employed/Career Path  115426\n",
       "10     Service Outcomes at exit Training/Education   27706\n",
       "11    Customer Satisfaction (participant/employer)  501335"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[['CATEGORY', '#']] # extract the rows 'category' and '#'\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>#</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assisted Service Clients</td>\n",
       "      <td>183059</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assisted Service Clients Age &lt; 20</td>\n",
       "      <td>10984</td>\n",
       "      <td>6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assisted Service Clients Age 20 -29</td>\n",
       "      <td>53087</td>\n",
       "      <td>29%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               CATEGORY       #    %\n",
       "1              Assisted Service Clients  183059  NaN\n",
       "2     Assisted Service Clients Age < 20   10984   6%\n",
       "3  Assisted Service Clients Age 20 -29    53087  29%"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1:4] # select rows 1:4 using .loc method from Pandas\n",
    "\n",
    "df.iloc[1:4] # select rows 1:3 using .iloc, which has sligtly differnt syntax but is basically equiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MISSION: Read and modify datasets\n",
    "\n",
    "In this mission, you will work with a large dataset and will practice how to extract and query information in the Mushrooms dataset using Pandas. \n",
    "\n",
    "Purpose: programming using the Pandas library to access in a dataset. \n",
    "\n",
    "To complete this mission, perform the following task in the editor provided:\n",
    "\n",
    "Step 1  \n",
    "\n",
    "You are now going to move on to a larger dataset with more attributes. Larger datasets behave the same as smaller datasets.\n",
    "\n",
    "This dataset is all about the mushroom and its many variations. Whether edible or poisonous, mushrooms have many traits that make up their classifications. This dataset lists different species' properties along with their edible/poisonous classifications.\n",
    "\n",
    "You can revisit the Mushrooms dataset here.\n",
    "\n",
    "License this is public CC0: Public Domain\n",
    "\n",
    "Dataset available here.\n",
    "\n",
    "Your code should perform the following tasks to complete this mission in the editor provided:\n",
    "\n",
    "       1. Load the mushrooms dataset from mushrooms.csv;\n",
    "\n",
    "       2. Extract data tuple with index 7 and its classification; and\n",
    "\n",
    "       3. Find out whether or not the mushroom with index 7 is edible.\n",
    "\n",
    "Your code should return one Boolean value, \"edible.\"\n",
    "\n",
    "HINT:\n",
    "\n",
    "You can index pandas.DataFrame with column names. The edible/poisonous classification is in a column called \"class.\"\n",
    "You can read the mushrooms dataset by the following code: dataset=read_csv('mushrooms.csv')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>e</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>k</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0        p         x           s         n       t    p               f   \n",
       "1        e         x           s         y       t    a               f   \n",
       "2        e         b           s         w       t    l               f   \n",
       "3        p         x           y         w       t    p               f   \n",
       "4        e         x           s         g       f    n               f   \n",
       "...    ...       ...         ...       ...     ...  ...             ...   \n",
       "8119     e         k           s         n       f    n               a   \n",
       "8120     e         x           s         n       f    n               a   \n",
       "8121     e         f           s         n       f    n               a   \n",
       "8122     p         k           y         n       f    y               f   \n",
       "8123     e         x           s         n       f    n               a   \n",
       "\n",
       "     gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0               c         n          k  ...                        s   \n",
       "1               c         b          k  ...                        s   \n",
       "2               c         b          n  ...                        s   \n",
       "3               c         n          n  ...                        s   \n",
       "4               w         b          k  ...                        s   \n",
       "...           ...       ...        ...  ...                      ...   \n",
       "8119            c         b          y  ...                        s   \n",
       "8120            c         b          y  ...                        s   \n",
       "8121            c         b          n  ...                        s   \n",
       "8122            c         n          b  ...                        k   \n",
       "8123            c         b          y  ...                        s   \n",
       "\n",
       "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                         w                      w         p          w   \n",
       "1                         w                      w         p          w   \n",
       "2                         w                      w         p          w   \n",
       "3                         w                      w         p          w   \n",
       "4                         w                      w         p          w   \n",
       "...                     ...                    ...       ...        ...   \n",
       "8119                      o                      o         p          o   \n",
       "8120                      o                      o         p          n   \n",
       "8121                      o                      o         p          o   \n",
       "8122                      w                      w         p          w   \n",
       "8123                      o                      o         p          o   \n",
       "\n",
       "     ring-number ring-type spore-print-color population habitat  \n",
       "0              o         p                 k          s       u  \n",
       "1              o         p                 n          n       g  \n",
       "2              o         p                 n          n       m  \n",
       "3              o         p                 k          s       u  \n",
       "4              o         e                 n          a       g  \n",
       "...          ...       ...               ...        ...     ...  \n",
       "8119           o         p                 b          c       l  \n",
       "8120           o         p                 b          v       l  \n",
       "8121           o         p                 b          c       l  \n",
       "8122           o         e                 w          v       l  \n",
       "8123           o         p                 o          c       l  \n",
       "\n",
       "[8124 rows x 23 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushrooms = pd.read_csv('mushrooms.csv') # load the mushrooms dataset\n",
    "\n",
    "mushrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract data tuple with index 7 and its classification\n",
    "\n",
    "shroom = mushrooms.loc[7]['class']\n",
    "\n",
    "shroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out whether mushroom with index 7 is edible\n",
    "\n",
    "edible = shroom == 'e'\n",
    "\n",
    "edible\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mission instructions:\n",
    "\n",
    "In this mission, you will work with the Iris dataset and will practice how to extract and use information from a dataset.\n",
    "\n",
    "To complete this mission, perform the following task in the editor provided:\n",
    "\n",
    "Step 1  \n",
    "\n",
    " Another rather popular built-in dataset is the Iris dataset. You will need to load it before continuing. The Iris dataset contains information about 3 types of the iris plant. The dataset contains 150 data tuples and their corresponding target labels. Each tuple consists of four attributes about a certain plant: sepal length, sepal width, petal length, and petal width (all in cm units), in that order. The target label is integer 0, 1, or 2, representing the tuple's classification as an Iris Setosa, an Iris Versicolor, or an Iris Virginica, respectively.\n",
    "\n",
    "Your code should perform the following tasks to complete this mission in the editor provided:\n",
    "\n",
    "       1. Load the Iris dataset from the Scikit-Learn library;\n",
    "\n",
    "       2. Extract data tuple with index 7 and its target; and\n",
    "\n",
    "       3. Extract the sepal width (in cm) of the plant with index 7 and its target label as integer 0, 1, or 2.\n",
    "\n",
    "Your code should return the lable of the seventh index’s sepal_width.\n",
    "\n",
    "HINT:\n",
    "\n",
    "The sepal width (in cm) is the element with index 1 in the data tuple.\n",
    "The Iris dataset is read by this code: from sklearn.datasets import load_iris dataset = load_iris()\n",
    "You can access the features of the dataset by \"dataset.data\" and the target by \"dataset.target\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the iris dataset\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "\n",
    "dataset = load_iris()\n",
    "\n",
    "features = dataset.data[7]\n",
    "    \n",
    "label = dataset.target[7]\n",
    "\n",
    "sepal_width = features[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "### Basic summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.857142857142857"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "x = [2,2,3,4,2,5,9]\n",
    "\n",
    "statistics.mean(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y = [2.5, 3.1, 3.4, 3.5, 3.5, 4, 4.1]\n",
    "\n",
    "mean = statistics.median(y)\n",
    "\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Initialize an array of zeroes\n",
    "\n",
    "np.zeros((2,2), dtype = float, order = 'C')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2. , 2. , 3. , 4. , 2. , 5. , 9. ],\n",
       "       [2.5, 3.1, 3.4, 3.5, 3.5, 4. , 4.1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,20, 2) # initialize an array from 1-20, ascending by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  3.11111111,  5.22222222,  7.33333333,  9.44444444,\n",
       "       11.55555556, 13.66666667, 15.77777778, 17.88888889, 20.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(1,20, 10) # 10 evenly spaced numbers from 1-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.asarray(x)\n",
    "\n",
    "z[2:5] # negative indices work too\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.857142857142857"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important terms\n",
    "\n",
    "**Noise**\n",
    "\n",
    "In analyzing data, we define noise as any distortion to the actual data points. Noise in data has two main types:\n",
    "- Noise in Objects: an extraneous object.\n",
    "- Noise in Attributes: distortion in original values of data.\n",
    "\n",
    "\n",
    "**Methods of dealing with missing data**\n",
    "\n",
    "- Eliminate data objects completely or only eliminate the missing values.\n",
    "- Fill in the missing data using the mode of the attribute or using an unbiased average of data.\n",
    "- Ignore missing values during analysis and assume values during testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dissimilarity measures\n",
    "\n",
    "**Properties of dissimilarity measures**\n",
    "\n",
    "- A numerical measure of how two data points are different from each other\n",
    "- Zero for two duplicate data points\n",
    "- No fixed upper limit (depending on the type of dis-similarity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission\n",
    "\n",
    "To complete this mission, perform the following tasks in the editor provided:\n",
    "\n",
    "Step 1\n",
    "\n",
    "You will now explore the Mushrooms dataset!\n",
    "\n",
    "Your code should perform the following tasks to complete this mission in the editor provided:\n",
    "\n",
    "Count the edible mushrooms species and calculate their percentage in the dataset.\n",
    "Extract all the unique cap colors in the dataset (n, y, w, etc.).\n",
    "Your code should return edible_count, edible_percentage, and cap_colors.\n",
    "\n",
    "Revisit the Mushroom dataset here.\n",
    "\n",
    "Hint: Import numpy library as it is essensial in this code by the following code.\n",
    "\n",
    "Hint:\n",
    "\n",
    "To get unique values of specific column of a dataframe, use the following function np.unique(dataset.iloc[:,0].values).\n",
    "You can get number of rows of a dataframe by using the following function: datasert.shape[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b' 'c' 'e' 'g' 'n' 'p' 'r' 'u' 'w' 'y']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# preamble\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "\n",
    "dataset = pd.read_csv('mushrooms.csv')\n",
    "\n",
    "edible = dataset.loc[dataset['class'] == 'e']\n",
    "\n",
    "edible_count = edible.shape[0]\n",
    "\n",
    "edible_percentage = (edible_count / dataset.shape[0])*100\n",
    "\n",
    "cap_colors = np.unique(dataset.loc[:,'cap-color'].values)\n",
    "\n",
    "print(cap_colours)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission\n",
    "\n",
    "\n",
    "To complete this mission, perform the following tasks in the editor provided:\n",
    "\n",
    "Step 1\n",
    "\n",
    "Now it is time for you to get a better look at the Iris dataset!\n",
    "\n",
    "Your code should perform the following tasks to complete this mission in the editor provided:\n",
    "\n",
    "Calculate the mean of all the attributes: sepal length, sepal width, petal length, and petal width.\n",
    "Calculate the variance of all the attributes: sepal length, sepal width, petal length, and petal width.\n",
    "Your code should return means and variances; each is a 1D array with 4 values for the sepal length, sepal width, petal length, and petal width, respectively.\n",
    "\n",
    "Hint: there are a lot of ways to do this, but you should consider taking a look at the built-in functions mean and var in NumPy or Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.843333333333335\n",
      "0    0.685694\n",
      "1    0.189979\n",
      "2    3.116278\n",
      "3    0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## actual way to do it\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "dataset = load_iris()\n",
    "\n",
    "dataset = pd.DataFrame(dataset['data'])\n",
    "\n",
    "means = np.asarray(dataset.mean())\n",
    "\n",
    "variances = np.asarray(dataset.var())\n",
    "\n",
    "print(np.max(means))\n",
    "\n",
    "print(variances)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3\n",
       "0    5.1  3.5  1.4  0.2\n",
       "1    4.9  3.0  1.4  0.2\n",
       "2    4.7  3.2  1.3  0.2\n",
       "3    4.6  3.1  1.5  0.2\n",
       "4    5.0  3.6  1.4  0.2\n",
       "..   ...  ...  ...  ...\n",
       "145  6.7  3.0  5.2  2.3\n",
       "146  6.3  2.5  5.0  1.9\n",
       "147  6.5  3.0  5.2  2.0\n",
       "148  6.2  3.4  5.4  2.3\n",
       "149  5.9  3.0  5.1  1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "dataset = load_iris()['data']\n",
    "\n",
    "pd.DataFrame(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Hacky way to do it \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "dataset = load_iris(as_frame=True)['DESCR']\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9166666666666665"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = (2,2,2,3,4,8,3,4,2,5,9,3)\n",
    "\n",
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "\n",
    "### Categorical data\n",
    "\n",
    "Categorical data is the type of data that can only have one of a limited set of values assigning each data object to a specific group or a nominal category.\n",
    "\n",
    "### Encodering\n",
    "\n",
    "Encoders are a module of machine learning models whose task is converting given information to a particular form so that a system can work with it. For example, if the input of an encoder is categorical data, the encoder will convert it to an integer array. Below, you will read more about different types of encoders.\n",
    "\n",
    "The Scikit-Learn library supports the following types of encoders:\n",
    "- Ordinal Encoder: encodes categorical features as an integer array.\n",
    "    - Pro: keeps data in one column\n",
    "    - Con: implies ordering when there sometimes isn't a natural one\n",
    "\n",
    "- One-hot Encoder: encodes only one category as 1 and all other categories as 0.\n",
    "     - Need to drop column to prevent multicolinearity\n",
    "\n",
    "\n",
    "- Label Encoder: encodes target labels with values between 0 and n_categories-1.\n",
    "\n",
    "#### Encoding target\n",
    "\n",
    "Use the Label Encoder from the sklearn.preprocessing library:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Feature scaling is a method used to standardize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step.\n",
    "\n",
    "Some machine learning models require input features to have zero mean and unit variance for better accuracy or to be able to learn from available data. To achieve that, we calculate the mean and variance of the data, subtract the mean from all data samples, then divide all data samples by the variance. That does not affect how the data looks, as we will see shortly, but it helps the machine learning model learn from the data.\n",
    "This is called feature standardization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission - Encoding\n",
    "\n",
    "Mission instructions:\n",
    "\n",
    "To complete this mission, perform the following task in the editor provided:\n",
    "\n",
    "Step 1    \n",
    "\n",
    "The Mushrooms dataset has a plethora of categorical attributes; you will now use it for practicing!\n",
    "\n",
    "Your code should perform the following tasks to complete this mission in the editor provided:\n",
    "\n",
    "Encode y (the class attribute) using LabelEncoder and\n",
    "Encode selected_X (a subset of attributes) using OneHotEncoder.\n",
    "Your code should return encoded_y and encoded_X, which are arrays with the transformed result of applying the encoders.\n",
    "\n",
    "HINT: encoded_y should be a 1D array with only 0s and 1s.\n",
    "HINT: encoded_X should be a 2D array with only 0s and 1s (the fit_transform function for a OneHotEncoder returns a sparse matrix by default; hence, to get an array, you can either disable the sparse option in the constructor (OneHotEncoder(sparse=False)) or call toarray() on the sparse matrix returned).\n",
    "HINT: knowing that selected_X has 2 columns with 6 unique values in the first and 4 unique values in the second, how many columns should encoded_X have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, ..., 0, 1, 0]),\n",
       " array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [1., 0., 0., ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main():    \n",
    "    import pandas as pd\n",
    "    dataset = pd.read_csv('mushrooms.csv')\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    ## Encode y\n",
    "\n",
    "    ### Select y as an array\n",
    "\n",
    "    y = dataset.iloc[:, 0].values\n",
    "\n",
    "    ### Fit encoder to y\n",
    "\n",
    "    y_encoder = LabelEncoder()\n",
    "\n",
    "    y_encoder.fit(y)\n",
    "\n",
    "    ### transform data\n",
    "\n",
    "    encoded_y = y_encoder.transform(y)\n",
    "\n",
    "    ## Encode x\n",
    "\n",
    "    selected_X = dataset.iloc[:, 1:3].values\n",
    "\n",
    "    X_encoder = OneHotEncoder(sparse=False) # returns a sparse matrix by default\n",
    "\n",
    "    X_encoder.fit(selected_X)\n",
    "\n",
    "    encoded_X = X_encoder.transform(selected_X)\n",
    "\n",
    "    print(encoded_X[0,:])\n",
    "\n",
    "    return encoded_y, encoded_X\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission - Scaling\n",
    "\n",
    "Mission instructions:\n",
    "\n",
    "To complete this mission, perform the following tasks in the editor provided:\n",
    "\n",
    "Step 1\n",
    "\n",
    "Time to practice scaling features! You will now return to the Iris dataset!\n",
    "\n",
    "Your code should perform the following tasks to complete this mission in the editor provided:\n",
    "\n",
    "Load the Iris dataset from scikit-learn as a data vector X and a label vector y and\n",
    "Scale the data vector X with a standard scaler (normalize X).\n",
    "Your code should return the scaled data vector scaled_X.\n",
    "\n",
    "SELF-CHECK: notice the result of calling mean(axis=0) and var(axis=0) (or var(axis=0)) for scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4684549872375404e-15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "### Scale X using standard scaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler = scaler.fit(X)\n",
    "\n",
    "scaled_X = scaler.transform(X)\n",
    "\n",
    "#uncomment the two lines after assigning the values to \"scaled_X\" in order to complete this mission\n",
    "\n",
    "print(np.mean(scaled_X))\n",
    "\n",
    "    #return scaled_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Representing the data with tools like graphs, charts, maps, and other data visualization tools makes it easier to observe and understand trends and patterns present within the information.\n",
    "Thus, data analysts rely mainly on the graphical representation of massive amounts of information to make it possible to provide data-driven decisions.\n",
    "You typically need to visualize data to select the most suitable machine learning model. You may also need to visualize the model to see how well it fits the data. You will use similar Python commands for that.\n",
    "\n",
    "### Components of a pyplot\n",
    "\n",
    "- Figure: the figure is the entire window where the plot is drawn, and it is the top-level component. It may also contain several subcomponents within to better describe the plotted graph.\n",
    "- Axes: they represent the area which the plot functions on Matplotlib would plot the data on.\n",
    "- Axes labels: a description of the values of each axis.\n",
    "- Plot title: a descriptive title of the plot.\n",
    "- Legend: a box showing description of each graph of a multi-graph plot."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "114c2fdb226e4dc103f00c2512f291967d93737a0d1ce45be4aa564dac2afe8e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
